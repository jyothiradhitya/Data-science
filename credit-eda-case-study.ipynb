{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":552038,"sourceType":"datasetVersion","datasetId":263888}],"dockerImageVersionId":30004,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', 200)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reading the csv file\napplication_data = pd.read_csv('/kaggle/input/credit-card/application_data.csv')","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the data\napplication_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the shape of the data\napplication_data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the info, dtypes\napplication_data.info(verbose=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"application_data.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# not much information is recieved through this.. we will check for percentages\napplication_data.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the percentage of null values in columns and filtering the columns with\n#more than or equal to 40% NULL values.\nnull_data_percentage = application_data.isnull().sum()*100/len(application_data)\nmajor_missing_data_columns = null_data_percentage[null_data_percentage>=40]\nmajor_missing_data_columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dropping the above columns from dataframe for further analysis\napplication_data_df = application_data.drop(columns=major_missing_data_columns.index)","metadata":{"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"application_data_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(application_data_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking if there is if NaN values in rows is greater than 50%\n# we see that none of the rows have more than 50% nan values. so we will proceed with further checks.\nmissing_rows = application_data_df.isnull().sum(axis=1)/application_data_df.shape[1]\nmissing_rows[missing_rows>50]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now we have dealt with the >=50% null values, we will now take care of null values which are in less than <=20%.  We won't be imputing the values, but will try to find values with which it can be imputed at a later point of time.","metadata":{}},{"cell_type":"code","source":"minor_missing_data_columns = null_data_percentage[(null_data_percentage<=15) & (null_data_percentage>0)].sort_values(ascending=False)\nminor_missing_data_columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### As we can see there are few columns with percentage of null values >0 and <=15 and then among these the columns which have percentage of null values between 0-1 are very few.So, for these columns we can either drop them or impute them with mode value respectively.\n#### For columns having missing values around 13%, we will check them individually and determine what would be the best possible value to impute them with.\n","metadata":{}},{"cell_type":"code","source":"application_data_df[['AMT_REQ_CREDIT_BUREAU_YEAR','AMT_REQ_CREDIT_BUREAU_MON','AMT_REQ_CREDIT_BUREAU_WEEK','AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_HOUR','AMT_REQ_CREDIT_BUREAU_QRT']].info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"application_data_df[['EXT_SOURCE_3','AMT_REQ_CREDIT_BUREAU_YEAR','AMT_REQ_CREDIT_BUREAU_MON','AMT_REQ_CREDIT_BUREAU_WEEK','AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_HOUR','AMT_REQ_CREDIT_BUREAU_QRT']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# since these columns are numeric type, we will chack the number of unique values each column contain.\nprint(\"AMT_REQ_CREDIT_BUREAU_YEAR unique values:\", application_data_df['AMT_REQ_CREDIT_BUREAU_YEAR'].nunique())\nprint(\"AMT_REQ_CREDIT_BUREAU_MON unique values:\", application_data_df['AMT_REQ_CREDIT_BUREAU_MON'].nunique())\nprint(\"AMT_REQ_CREDIT_BUREAU_WEEK unique values:\", application_data_df['AMT_REQ_CREDIT_BUREAU_WEEK'].nunique())\nprint(\"AMT_REQ_CREDIT_BUREAU_DAY unique values:\", application_data_df['AMT_REQ_CREDIT_BUREAU_DAY'].nunique())\nprint(\"AMT_REQ_CREDIT_BUREAU_HOUR unique values:\", application_data_df['AMT_REQ_CREDIT_BUREAU_HOUR'].nunique())\nprint(\"AMT_REQ_CREDIT_BUREAU_QRT unique values:\", application_data_df['AMT_REQ_CREDIT_BUREAU_QRT'].nunique())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### These columns give a sense that they might be categorical given such less unique values. we will check that and then will decide if the data type has to be changed accordingly.","metadata":{}},{"cell_type":"code","source":"application_data_df['AMT_REQ_CREDIT_BUREAU_YEAR'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"application_data_df['AMT_REQ_CREDIT_BUREAU_MON'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"application_data_df['AMT_REQ_CREDIT_BUREAU_WEEK'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"application_data_df['AMT_REQ_CREDIT_BUREAU_HOUR'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"application_data_df['AMT_REQ_CREDIT_BUREAU_DAY'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"application_data_df['AMT_REQ_CREDIT_BUREAU_QRT'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### as per the given discription these variables indicate number of days, hrs, months, etc. we can conclude that these are columns with categorical values.\n#### And regarding the null values, as it can be seen from the data above, since these are categorical columns, and there mode value is 0 for all these variables. so, it is safe to impute the null values with 0.","metadata":{}},{"cell_type":"code","source":"# we will check for unwanted columns\napplication_data_df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"application_data_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we found these cols to be unwanted/ not required so we will drop them for further analysis\nunwanted_cols = ['FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE','FLAG_EMAIL',\n          'REGION_RATING_CLIENT','REGION_RATING_CLIENT_W_CITY', 'FLAG_EMAIL','DAYS_LAST_PHONE_CHANGE',\n          'FLAG_DOCUMENT_2','REG_REGION_NOT_LIVE_REGION','REG_REGION_NOT_WORK_REGION',\n          'LIVE_REGION_NOT_WORK_REGION','FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4','FLAG_DOCUMENT_5',\n          'FLAG_DOCUMENT_6','FLAG_DOCUMENT_7','FLAG_DOCUMENT_8','FLAG_DOCUMENT_9','FLAG_DOCUMENT_10',\n          'FLAG_DOCUMENT_11','FLAG_DOCUMENT_12','FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14',\n          'FLAG_DOCUMENT_15','FLAG_DOCUMENT_16','FLAG_DOCUMENT_17','FLAG_DOCUMENT_18',\n          'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21']\n\napplication_data_df.drop(columns=unwanted_cols, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"application_data_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now we have the final dataframe for analysis.\n# we will now dive deep into details of variables to find out insights\napplication_data_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we will describe to have a better look at variables\napplication_data_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now that we have the final dataframe after dropping unwanted columns, we now check for dtypes of each columns and change their dtype based on the values they contain","metadata":{}},{"cell_type":"code","source":"application_data_df.nunique().sort_values()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we notice that till variable ORGANIZATION_TYPE all variables are categorical\n# so we will get their index and convert them to categorical columns\napplication_data_df.nunique().sort_values().index","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_cols = ['FLAG_MOBIL', 'TARGET', 'NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR',\n                    'FLAG_OWN_REALTY', 'REG_CITY_NOT_WORK_CITY','LIVE_CITY_NOT_WORK_CITY',\n                    'REG_CITY_NOT_LIVE_CITY','AMT_REQ_CREDIT_BUREAU_HOUR', 'NAME_EDUCATION_TYPE',\n                    'NAME_HOUSING_TYPE', 'NAME_FAMILY_STATUS', 'WEEKDAY_APPR_PROCESS_START',\n                    'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'AMT_REQ_CREDIT_BUREAU_DAY',\n                    'AMT_REQ_CREDIT_BUREAU_WEEK', 'DEF_60_CNT_SOCIAL_CIRCLE','DEF_30_CNT_SOCIAL_CIRCLE',\n                    'AMT_REQ_CREDIT_BUREAU_QRT', 'CNT_CHILDREN','CNT_FAM_MEMBERS','OCCUPATION_TYPE',\n                    'HOUR_APPR_PROCESS_START','AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_YEAR',\n                    'OBS_60_CNT_SOCIAL_CIRCLE','OBS_30_CNT_SOCIAL_CIRCLE','ORGANIZATION_TYPE']\nfor col in categorical_cols:\n    application_data_df[col] = application_data_df[col].astype('category')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SK_ID_CURR is int data type, but it holds id number of customers, and this variable cannot be manipulated\n# so we will convert it to object datatype\napplication_data_df['SK_ID_CURR'] = application_data_df['SK_ID_CURR'].astype('object')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we will check the dtypes again to confirm\napplication_data_df.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we notice that \"DAYS_BIRTH\"  'DAYS_EMPLOYED' 'DAYS_REGISTRATION' 'DAYS_ID_PUBLISH' columns have negative values,which is not not possible.\n# so we will try to correct this\napplication_data_df[['DAYS_BIRTH' ,'DAYS_EMPLOYED' ,'DAYS_REGISTRATION' ,'DAYS_ID_PUBLISH']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"application_data_df[['DAYS_BIRTH' ,'DAYS_EMPLOYED' ,'DAYS_REGISTRATION' ,'DAYS_ID_PUBLISH']].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''we will now convert negative values to positve values using abs() \nand then convert days into years for better understanding'''\n\ndays_cols = ['DAYS_BIRTH' ,'DAYS_EMPLOYED' ,'DAYS_REGISTRATION' ,'DAYS_ID_PUBLISH']\napplication_data_df[days_cols] = application_data_df[days_cols].abs()\napplication_data_df[days_cols] = application_data_df[days_cols]/365\napplication_data_df[days_cols].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### now that we have converted these values to years we need to update these column names as well to years","metadata":{}},{"cell_type":"code","source":"application_data_df.rename(columns={'DAYS_BIRTH':'YEARS_BIRTH' ,'DAYS_EMPLOYED':'YEARS_EMPLOYED' ,\n    'DAYS_REGISTRATION':'YEARS_REGISTRATION' ,'DAYS_ID_PUBLISH':'YEARS_ID_PUBLISH'}, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### we will check the object data type variables","metadata":{}},{"cell_type":"code","source":"# we will now check gendere column\napplication_data_df['CODE_GENDER'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# since gender varible contains categorical value, so we will replace XNA with F based on mode value\napplication_data_df.loc[application_data_df['CODE_GENDER']=='XNA', 'CODE_GENDER'] = 'F'\napplication_data_df['CODE_GENDER'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we will now check the'AMT_INCOME_TOTAL' and 'AMT_CREDIT' variables\napplication_data_df[['AMT_INCOME_TOTAL', 'AMT_CREDIT']].describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# it is hard to determine the type of customer based on these values as these are continous.\n# we will make make 2 new columns for these respectively  dividing them into categories for easy understanding\nbins = [0,100000,250000,500000,750000,1000000, 1250000, 1500000, 1750000, 2000000, 2250000,2500000,\n        2750000,3000000,3250000,3500000,3750000,4000000,4250000,4500000,4750000,5000000,150000000]\nranges = ['0-100000','100000-250000','250000-500000','500000-750000','750000-1000000', '1000000-1250000',\n          '1250000-1500000','1500000-1750000','1750000-2000000','2000000-2250000','2250000-2500000',\n          '2500000-2750000','2750000-3000000','3000000-3250000','3250000-3500000','3500000-3750000',\n          '3750000-4000000','4000000-4250000','4250000-4500000','4500000-4750000','4750000-5000000',\n          '5000000 and above']\n\napplication_data_df['AMT_INCOME_RANGE'] = pd.cut(application_data_df['AMT_INCOME_TOTAL'],bins,labels=ranges)\napplication_data_df['AMT_CREDIT_RANGE'] = pd.cut(application_data_df['AMT_CREDIT'],bins,labels=ranges)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"application_data_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,6)) \nsns.countplot(data=application_data_df,x='AMT_CREDIT_RANGE', hue='CODE_GENDER')\nplt.xticks(rotation=90)\nplt.legend(loc='upper right')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### checking for outliers","metadata":{}},{"cell_type":"code","source":"application_data_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The variables below have outliers. as viewed from the describe.\n#### now lets plot boxplots to view each of them individually","metadata":{}},{"cell_type":"code","source":"'''this variable indiactes Number of children the client has.\nas we see from the plot some values are as high as 19, which is not possible in general case scenario. \nhence an outlier'''\n\nsns.boxplot(application_data_df['CNT_CHILDREN'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''this  varibale indictes the Income of the client.\nas we can see from the plot there is one value which is too high compared to others.\nhence it is an outlier.\n'''\n\nsns.boxplot(application_data_df['AMT_INCOME_TOTAL'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#this output proves that it is an outlier since the person here has occupation type as labourer, and her target variable is 1. \napplication_data_df[application_data_df['AMT_INCOME_TOTAL'] == application_data_df['AMT_INCOME_TOTAL'].max()]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nthis variable indicates Credit amount of the loan\nas we can see from the graph there are few outliers.\nwe will check these values to confirm.\n\n'''\n\nsns.boxplot(application_data_df['AMT_CREDIT'])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# as we can see from tehe values below, the AMT_CRDIT  is greater than AMT_INCOME_TOTAL in all the cases\n#and then its greater than most values\napplication_data_df[application_data_df['AMT_CREDIT']> 3.5*1e6]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nthis variable indicates How many years before the application the person started current employment?\nas we can see from the plot below the outlier value is 1000 yrs. which makes the case for it being an outlier\n\n'''\nsns.boxplot(application_data_df['YEARS_EMPLOYED'])\nplt.show() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nthis variable indicates the  Number of enquiries to Credit Bureau about the client 3 month\nbefore application (excluding one month before application)\nas we can see from the plot below there is one outlier.\n\n'''\nsns.boxplot(application_data_df['AMT_REQ_CREDIT_BUREAU_QRT'])\nplt.show() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### we will divide the application dataset into two different dataframes based on target variable's value.\n### appli_data_target0 and appli_data_target1  for values 0 and 1 respectively\n\n### check for imbalance of data\n","metadata":{}},{"cell_type":"code","source":"#checking the distribution of target variable\nsns.countplot(application_data['TARGET'])\nplt.xlabel(\"TARGET Value\")\nplt.ylabel(\"Count of TARGET value\")\nplt.title(\"Distribution of TARGET Variable\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"application_data_df['TARGET'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating new datadrame for target=0\nappli_data_target0 = application_data_df[application_data_df['TARGET']==0]\nappli_data_target0.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the shape of new dataframe\nappli_data_target0.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating new datadrame for target=0\nappli_data_target1 = application_data_df[application_data_df['TARGET']==1]\nappli_data_target1.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the shape of the new dataframe\nappli_data_target1.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to get the ratio of appli_data_target0 : appli_data_target1\nratio = appli_data_target0.shape[0]/appli_data_target1.shape[0]\nratio","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### so basically the ratio of 0:1 is 11.387:1\n### this indiactes that for every 1 there are almost 11 number of 0's. this is a higlhy imbalanced data set\n","metadata":{}},{"cell_type":"markdown","source":"## we will now find the correlation between different variables for both dataframes with target=1 and target=0","metadata":{}},{"cell_type":"code","source":"# for target variable=0\nplt.figure(figsize=(12,8)) \nsns.heatmap(appli_data_target0.corr(), annot=True, cmap=\"coolwarm\")\nplt.title('Correlation matrix for target variable 0')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now we need to find top 10 correlations\ncorr0 = appli_data_target0.corr()\ncorr_df0 = corr0.where(np.triu(np.ones(corr0.shape), k=1).astype(np.bool))\ncorr_df0 = corr_df0.unstack().reset_index().dropna(subset = [0])\ncorr_df0.columns = ['VAR1', 'VAR2', 'Correlation_Value']\ncorr_df0['Corr_abs'] = abs(corr_df0['Correlation_Value'])\ncorr_df0.sort_values(by = \"Corr_abs\", ascending =False, inplace = True)\ncorr_df0.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for target variable=1\nplt.figure(figsize=(12,8)) \nsns.heatmap(appli_data_target1.corr(), annot=True, cmap=\"coolwarm\")\nplt.title('Correlation matrix for target variable 1')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now we need to find top 10 correlations\ncorr1 = appli_data_target1.corr()\ncorr_df1 = corr1.where(np.triu(np.ones(corr1.shape), k=1).astype(np.bool))\ncorr_df1 = corr_df1.unstack().reset_index().dropna(subset = [0])\ncorr_df1.columns = ['VAR1', 'VAR2', 'Correlation_Value']\ncorr_df1['Corr_abs'] = abs(corr_df1['Correlation_Value'])\ncorr_df1.sort_values(by = \"Corr_abs\", ascending =False, inplace = True)\ncorr_df1.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### As we can see from the top 10 correlations from both the dataframes, the top 3 correlations for both are almost similar.","metadata":{}},{"cell_type":"markdown","source":"### Univariate Analysis","metadata":{}},{"cell_type":"markdown","source":"#### for numerical variables","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.boxplot(appli_data_target0['YEARS_BIRTH'])\nplt.title('Customer without payment difficulties')\n\nplt.subplot(1,2,2)\nax = sns.boxplot(appli_data_target1['YEARS_BIRTH'])\nplt.title('Customer with payment difficulties')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### From the above box plot  we can note that customer without payment difficulties having year in between 34 to 54 years , And coustomer with payment difficulties having in between 31 to 50 years.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.boxplot(appli_data_target0[appli_data_target0['YEARS_EMPLOYED']<1000]['YEARS_EMPLOYED'])\nplt.title('Customer without payment difficulties')\n\nplt.subplot(1,2,2)\nax = sns.boxplot(appli_data_target1[appli_data_target1['YEARS_EMPLOYED']<1000]['YEARS_EMPLOYED'])\nplt.title('Customer with payment difficulties')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### From the above box plot  we can note that customer without payment difficulties having year in between 34 to 54 years , And coustomer with payment difficulties having in between 31 to 50 years.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.boxplot(appli_data_target0['AMT_GOODS_PRICE'])\nplt.title('Customer without payment difficulties')\n\nplt.subplot(1,2,2)\nax = sns.boxplot(appli_data_target1['AMT_GOODS_PRICE'])\nplt.title('Customer with payment difficulties')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here we can see that the customer without payment difficulties lies in between 0.3 to 0.7 and the customer with payment difficulties lies in between the same as of the without payment 0.3 to 0.7. And also both are having the mid value about 0.5.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.boxplot(appli_data_target0['YEARS_ID_PUBLISH'])\nplt.title('Customer without payment difficulties')\n\nplt.subplot(1,2,2)\nax = sns.boxplot(appli_data_target1['YEARS_ID_PUBLISH'])\nplt.title('Customer with payment difficulties')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here we can see that the customer without payment difficulties lies in between 5 to 11 and Here we can see that the customer with payment difficulties lies in between 3 to 11","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.boxplot(appli_data_target0['AMT_ANNUITY'])\nplt.title('Customer without payment difficulties')\n\nplt.subplot(1,2,2)\nax = sns.boxplot(appli_data_target1['AMT_ANNUITY'])\nplt.title('Customer with payment difficulties')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### For Categorical Variables","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.countplot(appli_data_target0['NAME_CONTRACT_TYPE'])\nplt.title('Customer without payment difficulties')\n\nplt.subplot(1,2,2)\nax = sns.countplot(appli_data_target1['NAME_CONTRACT_TYPE'])\nplt.title('Customer with payment difficulties')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here we can see that the customer without payment and customer with payment difficulties both are taking cash loans.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.countplot(appli_data_target0['CODE_GENDER'])\nplt.title('Customer without payment difficulties')\n\nplt.subplot(1,2,2)\nax = sns.countplot(appli_data_target1['CODE_GENDER'])\nplt.title('Customer with payment difficulties')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here we can see that the female customer is having highest count as compare to male customes in both the cases","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.countplot(appli_data_target0['NAME_EDUCATION_TYPE'])\nplt.title('Customer without payment difficulties')\nplt.xticks(rotation=90)\n\nplt.subplot(1,2,2)\nax = sns.countplot(appli_data_target1['NAME_EDUCATION_TYPE'])\nplt.title('Customer with payment difficulties')\nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here we can see that the customer having payment difficulties in secondary/ secondary special in both the cases.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.countplot(appli_data_target0['NAME_HOUSING_TYPE'])\nplt.title('Customer without payment difficulties')\nplt.xticks(rotation=90)\n\nplt.subplot(1,2,2)\nax = sns.countplot(appli_data_target1['NAME_HOUSING_TYPE'])\nplt.title('Customer with payment difficulties')\nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here we have the payment difficulties in home/ apartment in both the cases. And we can also say that customers take loan for house/ apartment in compare to others.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.countplot(appli_data_target0['OCCUPATION_TYPE'])\nplt.title('Customer without payment difficulties')\nplt.xticks(rotation=90)\n\nplt.subplot(1,2,2)\nax = sns.countplot(appli_data_target1['OCCUPATION_TYPE'])\nplt.title('Customer with payment difficulties')\nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here we can see that laborers are having more difficulties in repaying the loan and also the core staff and the sales staff. But in the case of laborers those wo have without payment is way more then with having the payment.","metadata":{}},{"cell_type":"markdown","source":"### Bivariate Analysis\n\n#### Numerical-Numerical bivariate analysis","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.scatterplot(data=appli_data_target0[appli_data_target0['YEARS_EMPLOYED']<1000], x='YEARS_EMPLOYED',y='AMT_INCOME_TOTAL')\nplt.title('Customer without payment difficulties')\n\nplt.subplot(1,2,2)\nax = sns.scatterplot(data=appli_data_target1[appli_data_target1['YEARS_EMPLOYED']<1000], x='YEARS_EMPLOYED',y='AMT_INCOME_TOTAL')\nplt.title('Customer with payment difficulties')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.scatterplot(data=appli_data_target0,x='AMT_CREDIT',y='AMT_GOODS_PRICE')\nplt.title('Customer without payment difficulties')\n\n\nplt.subplot(1,2,2)\nax = sns.scatterplot(data=appli_data_target1,x='AMT_CREDIT',y='AMT_GOODS_PRICE')\nplt.title('Customer with payment difficulties')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### we can see that goods price is positively correlated with credit amount.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.scatterplot(data=appli_data_target0,x='AMT_CREDIT',y='AMT_ANNUITY')\nplt.title('Customer without payment difficulties')\n\n\nplt.subplot(1,2,2)\nax = sns.scatterplot(data=appli_data_target1,x='AMT_CREDIT',y='AMT_ANNUITY')\nplt.title('Customer with payment difficulties')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### People without payment difficuties take more credit for the annuity that they have","metadata":{}},{"cell_type":"markdown","source":"#### categorical - categorical bivariate analysis","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.countplot(data=appli_data_target0,x='NAME_CONTRACT_TYPE',hue='AMT_CREDIT_RANGE')\nplt.title('Customer without payment difficulties')\nplt.legend(loc='upper right')\n\n\nplt.subplot(1,2,2)\nax = sns.countplot(data=appli_data_target1,x='NAME_CONTRACT_TYPE',hue='AMT_CREDIT_RANGE')\nplt.title('Customer with payment difficulties')\nplt.legend(loc='upper right')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.countplot(data=appli_data_target0,x='CODE_GENDER',hue='AMT_INCOME_RANGE')\nplt.title('Customer without payment difficulties')\nplt.legend(loc='upper right')\n\n\nplt.subplot(1,2,2)\nax = sns.countplot(data=appli_data_target1,x='CODE_GENDER',hue='AMT_INCOME_RANGE')\nplt.title('Customer with payment difficulties')\nplt.legend(loc='upper right')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### numerical- categorical bivariate analysis","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.boxplot(data=appli_data_target0,y='AMT_CREDIT',x='NAME_EDUCATION_TYPE')\nplt.title('Customer without payment difficulties')\nplt.xticks(rotation=90)\n\nplt.subplot(1,2,2)\nax = sns.boxplot(data=appli_data_target1,y='AMT_CREDIT',x='NAME_EDUCATION_TYPE')\nplt.title('Customer with payment difficulties')\nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here we can see that the range of customers without payment of Academic degree is higher than the customer of with payment. And the rest of the Education type is almost same for both the cases.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.boxplot(data=appli_data_target0[appli_data_target0['AMT_INCOME_TOTAL']<5000000],y='AMT_INCOME_TOTAL',x='NAME_EDUCATION_TYPE')\nplt.title('Customer without payment difficulties')\nplt.xticks(rotation=90)\n\nplt.subplot(1,2,2)\nax = sns.boxplot(data=appli_data_target1[appli_data_target1['AMT_INCOME_TOTAL']<5000000],y='AMT_INCOME_TOTAL',x='NAME_EDUCATION_TYPE')\nplt.title('Customer with payment difficulties')\nplt.xticks(rotation=90)\nplt.show()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here we can see that the customers without payment is having more outliers as compare to the customer with payment.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,8)) \n\nplt.subplot(1,2,1)\nax = sns.boxplot(data=appli_data_target0,y='AMT_CREDIT',x='OCCUPATION_TYPE')\nplt.title('Customer without payment difficulties')\nplt.xticks(rotation=90)\n\nplt.subplot(1,2,2)\nax = sns.boxplot(data=appli_data_target1,y='AMT_CREDIT',x='OCCUPATION_TYPE')\nplt.title('Customer with payment difficulties')\nplt.xticks(rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here we can see that the range of the customers without payment more as compare to the customers with payment.","metadata":{}},{"cell_type":"markdown","source":"## Merging application_data_df and previous_application_df","metadata":{}},{"cell_type":"code","source":"#reading the previous application file\nprevious_application_df = pd.read_csv('/kaggle/input/credit-card/previous_application.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the data\nprevious_application_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the shape of the file\nprevious_application_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the info about the file\nprevious_application_df.info()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the percentiles, min values for the file\nprevious_application_df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"application_data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"previous_application_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merging the application_data with previous application data\nall_data_df = pd.merge(left=application_data, right=previous_application_df,how='inner', on='SK_ID_CURR',suffixes='_x')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking the new dataframe's shape\nall_data_df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we will check the percentages of each type of contract status\nall_data_df['NAME_CONTRACT_STATUS'].value_counts()*100/len(all_data_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(all_data_df['NAME_CONTRACT_STATUS'])\nplt.xlabel(\"Contract Status\")\nplt.ylabel(\"Count of Contract Status\")\nplt.title(\"Distribution of Contract Status\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#dividing the new dataframe into 4 parts based on the contract status, i.e: Approved, refused, canceled, unused","metadata":{}},{"cell_type":"code","source":"approved_df = all_data_df[all_data_df['NAME_CONTRACT_STATUS']=='Approved']\nrefused_df = all_data_df[all_data_df['NAME_CONTRACT_STATUS']=='Refused']\ncanceled_df = all_data_df[all_data_df['NAME_CONTRACT_STATUS']=='Canceled']\nunused_df = all_data_df[all_data_df['NAME_CONTRACT_STATUS']=='Unused offer']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now that we know the different status of the loan. we will now examine the variables based on this, so as to get an idea of which varibale is doing what.","metadata":{}},{"cell_type":"code","source":"all_data_df['NAME_CONTRACT_TYPEx'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2,ncols=2, figsize=(15,10),sharey=True)\n\nax1 = sns.countplot(ax=ax1,data=approved_df,x='NAME_CONTRACT_TYPEx')\nax1.set_title(\"Refused\", fontsize=10)\nax1.set_xlabel('NAME_CONTRACT_TYPEx')\nax1.set_ylabel(\"Number of Loans\")\n# ax1.set_xticklabels(ax1.get_xticklabels(),rotation=90)\n\nax2 = sns.countplot(ax=ax2,data=refused_df,x='NAME_CONTRACT_TYPEx')\nax2.set_title(\"Approved\", fontsize=10)\nax2.set_xlabel('NAME_CONTRACT_TYPEx')\nax2.set_ylabel(\"Number of Loans\")\n# ax2.set_xticklabels(ax2.get_xticklabels(),rotation=90)\n\nax3 = sns.countplot(ax=ax3,data=canceled_df,x='NAME_CONTRACT_TYPEx')\nax3.set_title(\"Canceled\", fontsize=10)\nax3.set_xlabel('NAME_CONTRACT_TYPEx')\nax3.set_ylabel(\"Number of Loans\")\n# ax3.set_xticklabels(ax3.get_xticklabels(),rotation=90)\n\nax4 = sns.countplot(ax=ax4,data=unused_df,x='NAME_CONTRACT_TYPEx')\nax4.set_title(\"Unused\", fontsize=10)\nax4.set_xlabel('NAME_CONTRACT_TYPEx')\nax4.set_ylabel(\"Number of Loans\")\n# ax4.set_xticklabels(ax4.get_xticklabels(),rotation=90)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here we can see that the Revolving loan is much more acceptable as compare to the cash and consumer loans.","metadata":{}},{"cell_type":"markdown","source":"### as we can see that to visualize 4 plots we wrote same code multiple times.  so to avoid redundancy, and to save our time, we will put the above code in a function and generalize it for our following plots, so that its easy to visualize and saves time","metadata":{}},{"cell_type":"code","source":"def multi_plot(variable_name):\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2,ncols=2, figsize=(15,12), sharey='all')\n    fig.tight_layout(pad=10.0)\n\n    ax1 = sns.countplot(ax=ax1,data=approved_df,x=variable_name)\n    ax1.set_title(\"Refused\", fontsize=10)\n    ax1.set_ylabel(\"Number of Loans\")\n    ax1.set_xticklabels(ax1.get_xticklabels(),rotation=90)\n\n    ax2 = sns.countplot(ax=ax2,data=refused_df,x=variable_name)\n    ax2.set_title(\"Approved\", fontsize=10)\n    ax2.set_ylabel(\"Number of Loans\")\n    ax2.set_xticklabels(ax2.get_xticklabels(),rotation=90)\n\n    ax3 = sns.countplot(ax=ax3,data=canceled_df,x=variable_name)\n    ax3.set_title(\"Canceled\", fontsize=10)\n    ax3.set_xlabel(variable_name)\n    ax3.set_ylabel(\"Number of Loans\")\n    ax3.set_xticklabels(ax3.get_xticklabels(),rotation=90)\n\n    ax4 = sns.countplot(ax=ax4,data=unused_df,x=variable_name)\n    ax4.set_title(\"Unused\", fontsize=10)\n    ax4.set_xlabel(variable_name)\n    ax4.set_ylabel(\"Number of Loans\")\n    ax4.set_xticklabels(ax4.get_xticklabels(),rotation=90)\n    \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multi_plot('NAME_CLIENT_TYPE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here we can see that the Repeater is getting more Refused but also we can see that the it also getting more apporved and even that it is getting more canceled and more usused.","metadata":{}},{"cell_type":"code","source":"multi_plot('CODE_GENDER')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here we can see that Female is getting more Refused more approved more canceled more unused but in case of male it is having average in every category.","metadata":{}},{"cell_type":"code","source":"multi_plot('NAME_EDUCATION_TYPE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here we can see that Secondary/ Secondary special is more effective in every case ","metadata":{}},{"cell_type":"code","source":"multi_plot('NAME_INCOME_TYPE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here we can see that the working type people are applying more loans as compare to others and also Commercial associates people are taking more loans.","metadata":{}},{"cell_type":"code","source":"multi_plot('NAME_FAMILY_STATUS')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here we can see that the Married people are applying and taking loans more than the others.","metadata":{}},{"cell_type":"code","source":"multi_plot('NAME_PAYMENT_TYPE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here we can see that the people are taking more loan in format of cash through the bank.","metadata":{}},{"cell_type":"code","source":"multi_plot('NAME_PORTFOLIO')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here most approved loan were through POS and Most refused loans were in cash.","metadata":{}},{"cell_type":"code","source":"multi_plot('OCCUPATION_TYPE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here laborers are getting most refused and most approved loans. And aslo Sales staff is also getting the second most refused and approved loans.","metadata":{}},{"cell_type":"code","source":"multi_plot('NAME_GOODS_CATEGORY')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Here Most Refused loan is of Mobile and most approved loan is Mobile","metadata":{}},{"cell_type":"code","source":"multi_plot('PRODUCT_COMBINATION')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The most accepting loan is Cash X-sell: low And most canceled loan is Cash and Most Unused loan is POS mobile with interest.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusion","metadata":{}},{"cell_type":"markdown","source":"#### Banks should focus more on contract type ‘Student’ ,’pensioner’ and ‘Businessman’ with housing ‘type other than ‘Co-op apartment’ for successful payments.\n\n#### Banks should focus less on income type ‘Working’ as they are having most number of unsuccessful payments.\n\n#### Also with loan purpose ‘Repair’ is having higher number of unsuccessful payments on time.\n\n#### Get as much as clients from housing type ‘With parents’ as they are having least number of unsuccessful payments.\n","metadata":{}}]}